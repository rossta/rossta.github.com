<!doctype html>
<html class="antialiased" lang="en">
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1.0,minimum-scale=1.0,maximum-scale=1.0,user-scalable=no" />
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<title>How to write a simple web crawler in Ruby - revisited - rossta.net</title>
<meta name="description" content="Bringing a fresh perspective and Ruby's Enumerator to revisit an old post on using Ruby to write a simple web crawler" />
<meta name="keywords" content="Ruby" />
<meta itemprop="name" content="How to write a simple web crawler in Ruby - revisited" />
<meta itemprop="description" content="Bringing a fresh perspective and Ruby's Enumerator to revisit an old post on using Ruby to write a simple web crawler" />
<meta itemprop="image" content="https://rossta.net/assets/images/blog/stock/spider-web-pexels-photo.jpg" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="rossta.net" />
<meta name="twitter:url" content="https://rossta.net/blog/how-to-write-a-simple-web-crawler-in-ruby-revisited.html" />
<meta name="twitter:title" content="How to write a simple web crawler in Ruby - revisited" />
<meta name="twitter:description" content="Bringing a fresh perspective and Ruby's Enumerator to revisit an old post on using Ruby to write a simple web crawler" />
<meta name="twitter:image" content="https://rossta.net/assets/images/blog/stock/spider-web-pexels-photo.jpg" />
<meta property="og:url" content="https://rossta.net/blog/how-to-write-a-simple-web-crawler-in-ruby-revisited.html" />
<meta property="og:type" content="website" />
<meta property="og:title" content="How to write a simple web crawler in Ruby - revisited" />
<meta property="og:image" content="https://rossta.net/assets/images/blog/stock/spider-web-pexels-photo.jpg" />
<meta property="og:description" content="Bringing a fresh perspective and Ruby's Enumerator to revisit an old post on using Ruby to write a simple web crawler" />
<meta property="og:site_name" content="rossta.net" />
<meta property="og:locale" content="en_US" />
<link rel="separator" href="-" />
    <meta charset="utf-8" />
    <meta http-equiv='X-UA-Compatible' content='IE=edge;chrome=1' />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="mobile-web-app-capable" content="yes">

    <link rel="pingback" href="https://webmention.io/rossta.net/xmlrpc" />
    <link rel="webmention" href="https://webmention.io/rossta.net/webmention" />
    <link rel="canonical" href="https://rossta.net/blog/how-to-write-a-simple-web-crawler-in-ruby-revisited.html" />
    <script type="application/ld+json">
      {"@context":"https://schema.org","@type":"Article","publisher":{"@type":"Organization","name":"Ross Kaffenberger"},"author":{"@type":"Person","name":"Ross Kaffenberger","image":{"@type":"ImageObject","url":"https://rossta.net/assets/images/me.jpg","width":400,"height":400},"url":"https://rossta.net","sameAs":["https://rossta.net/about/","https://twitter.com/rossta"]},"headline":"How to write a simple web crawler in Ruby - revisited","url":{"scheme":"https","user":null,"password":null,"host":"rossta.net","port":null,"path":"/blog/how-to-write-a-simple-web-crawler-in-ruby-revisited.html","query":null,"fragment":null},"datePublished":"2016-01-27T00:00:00Z","keywords":"ruby","description":"Bringing a fresh perspective and Ruby's Enumerator to revisit an old post on using Ruby to write a simple web crawler","mainEntityOfPage":{"@type":"WebPage","@id":"https://rossta.net"}}
    </script>


    <link rel="stylesheet" href="/css/app.f7bb33b95ea908b47d5f.css" media="all"></link>
    <script async defer data-domain="rossta.net" src="https://plausible.io/js/plausible.outbound-links.js"></script>
  </head>
  <body id="application" class="leading-relaxed">
    <header id="welcome-nav" class="top-bar text-gray-800 sm:flex sm:justify-between sm:items-center sm:px-4 sm:py-3" data-topbar>
  <div class="flex justify-between items-center px-4 py-3 sm:p-0">
    <h1 class="text-2xl font-bold">
      <a class="logo" href="/"><span>rossta.net</span></a>
    </h1>
    <button type="button" aria-label="Menu" class="top-bar-menu-button sm:hidden block text-gray-500 hover:text-gray-700 focus:text-gray-700 focus:outline-none">
      <svg class="h-6 w-6 fill-current" viewBox="0 0 24 24">
        <path class="icon" d="M4 5h16a1 1 0 0 1 0 2H4a1 1 0 1 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2zm0 6h16a1 1 0 0 1 0 2H4a1 1 0 0 1 0-2z"/>
        <path class="icon hidden" d="M18.278 16.864a1 1 0 0 1-1.414 1.414l-4.829-4.828-4.828 4.828a1 1 0 0 1-1.414-1.414l4.828-4.829-4.828-4.828a1 1 0 0 1 1.414-1.414l4.829 4.828 4.828-4.828a1 1 0 1 1 1.414 1.414l-4.828 4.829 4.828 4.828z"/>
      </svg>
    </button>
  </div>
  <nav class="top-bar-section hidden sm:block sm:flex sm:justify-around px-2 pt-2 pb-4">
    <a class="block px-2 py-1 hover:bg-green-200 sm:mt-0 sm:ml-2 mt-1" href="/blog/">blog</a>
    <a class="block px-2 py-1 hover:bg-green-200 sm:mt-0 sm:ml-2 mt-1" href="/series/">series</a>
    <a class="block px-2 py-1 hover:bg-green-200 sm:mt-0 sm:ml-2 mt-1" href="/talks/">talks</a>
    <a class="block px-2 py-1 hover:bg-green-200 sm:mt-0 sm:ml-2 mt-1" href="/projects/">projects</a>
    <a class="block px-2 py-1 hover:bg-green-200 sm:mt-0 sm:ml-2 mt-1" href="/about/">about</a>
    <a class="block px-2 py-1 hover:bg-green-200 sm:mt-0 sm:ml-2 mt-1" href="/feed.xml">feed</a>
  </nav>
</header>

    <main id="main" role="main" class="layout container">
        <article class="post mb-12">
    <header class="page-header mt-4">
  <h1>
    How to write a simple web crawler in Ruby - revisited
  </h1>
    <h2 class="mt-4 text-gray-600 font-medium">
      Crawling websites and streaming structured data with Ruby's Enumerator
    </h2>
</header>

    <p>Let&#39;s build a simple web crawler in Ruby. For inspiration, I&#39;d like to
to revisit <a href="http://www.skorks.com/2009/07/how-to-write-a-web-crawler-in-ruby/" target="_blank" rel="noopener noreferrer">Alan Skorkin&#39;s How to Write a Simple Web Crawler in Ruby</a> and attempt to achieve something similar with a fresh perspective.</p>

<p>We&#39;ll adapt Skork&#39;s original goals and provide a few of our own:</p>

<ul>
<li>must be able to crawl just a single domain</li>
<li>must be able to limit number of pages to crawl</li>
<li>the results should be represented as structured data so we don&#39;t have an incomprehensible soup of content</li>
<li>the results should be enumerable so we can have flexibility in how they&#39;re handled</li>
</ul>

<aside class="callout panel">
<p>
  Caveats! Please keep in mind that there are, of course, <a href="http://webscraper.io/">many</a> <a href="http://scrapy.org/">resources</a> for
  using resilient, well-tested <a href="https://www.import.io/">crawlers</a> in a variety of languages. We have mere academic intentions
  here so we choose to ignore many important concerns, such as client-side rendering, parallelism, and handling failure, as a matter of convenience.
</p>
</aside>

      <h3 id="breaking-it-down" class="title title-h3">
        <a name="breaking-it-down" class="anchor" href="#breaking-it-down">       <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16">
       <path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path>
       </svg>
</a>
        Breaking it down
      </h3>
    
<p>For this exercise, we&#39;re going to crawl <a href="http://www.programmableweb.com/" target="_blank" rel="noopener noreferrer">Programmable Web</a> to extract data from their <a href="http://www.programmableweb.com/apis/directory" target="_blank" rel="noopener noreferrer">API directory</a>.</p>

<p>Rather than take the naive approach of grabbing all content from any page, we&#39;re going to build a webcrawler that emits
structured data. Traversing from the first page of the api directory, our
crawler will visit web pages like a nodes of a tree, collecting data and
additional urls along the way.</p>

<p>Imagine that the results of our web crawl as a nested collection of
hashes with meaningful key-value pairs.</p>

<pre><code class="ruby"># results
[
  {
    name: &quot;Google Maps&quot;,
    api_provider: &quot;https://google.com&quot;
    api_homepage: &quot;https://developers.google.com/maps/&quot;
    categories: [&quot;Mapping&quot;, &quot;Viewer&quot;],
    provider_formats: [&quot;JSON&quot;, &quot;KML&quot;, &quot;XML&quot;]
    ...
  },
  {
    name: &quot;Twitter&quot;,
    api_provider: &quot;https://twitter.com&quot;
    api_homepage: &quot;https://dev.twitter.com/rest/public&quot;
    categories: [&quot;Social&quot;, &quot;Blogging&quot;],
    provider_formats: [&quot;Atom&quot;, &quot;JSON&quot;, &quot;REST&quot;, &quot;RSS&quot;, &quot;XML&quot;]
    ...
  },
]
</code></pre>

<aside class="callout panel">
<p>
  When using a web crawler, be aware of the limitations described in the website's <a href="https://en.wikipedia.org/wiki/Robots_exclusion_standard">robots.txt</a> file. In this post, we skip automated parsing and detection of <a href="http://www.programmableweb.com/robots.txt">Programmable Web's robots.txt</a> to filter out blacklisted urls and set a crawl delay dynamically. If you choose to run this code on your own, please crawl responsibly.
</p>
</aside>

      <h3 id="designing-the-surface" class="title title-h3">
        <a name="designing-the-surface" class="anchor" href="#designing-the-surface">       <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16">
       <path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path>
       </svg>
</a>
        Designing the surface
      </h3>
    
<p>If you&#39;ve been following my posts lately, you know that <a href="https://rossta.net/blog/ruby-enumerable.html" target="_blank" rel="noopener noreferrer">I love Enumerable</a> and you may not be surprised that I&#39;d like to model our structured, website data with an <a href="/blog/what-is-enumerator.html">Enumerator</a>. This will provide a familiar, flexible interface that can be adapted for logging, storage, transformation, and a wide range of use cases.</p>

<p>I want to simply ask a <code>spider</code> object for its results and get back an enumerator:</p>

<pre><code class="ruby">spider.results
=&gt; #&lt;Enumerator: ...&gt;
</code></pre>

<p>We&#39;ll be able to do some interesting things, like stream the
results lazily into a flexible storage engine, e.g. <a href="https://www.mongodb.org/" target="_blank" rel="noopener noreferrer">mongodb</a> or <code>PStore</code>,
available from the <a href="http://ruby-doc.org/stdlib-2.3.0/libdoc/pstore/rdoc/PStore.html" target="_blank" rel="noopener noreferrer">Ruby standard library</a>:</p>

<pre><code class="ruby">require &quot;pstore&quot;
store  = PStore.new(&quot;api_directory.pstore&quot;)

# create `spider`, then ...

spider.results.lazy.take(50).each_with_index do |result, i|
  store.transaction do
    store[result[:name]] = result
    store.commit
  end
end
</code></pre>

      <h3 id="writing-the-crawler" class="title title-h3">
        <a name="writing-the-crawler" class="anchor" href="#writing-the-crawler">       <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16">
       <path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path>
       </svg>
</a>
        Writing the crawler
      </h3>
    
<p>We&#39;re going to write a <code>Spider</code> class to enumerate website data. Our spider implementation borrows heavily from <a href="https://github.com/joeyAghion/spidey" target="_blank" rel="noopener noreferrer">joeyAghion&#39;s spidey</a> gem, described as a &quot;loose framework for crawling and scraping websites&quot; and Python&#39;s venerable <a href="http://scrapy.org/" target="_blank" rel="noopener noreferrer">Scrapy</a> project, which allows you to scrape websites &quot;in a fast, simple, yet extensible way.&quot; Both resources achieve the goals of being easy-to-use and extensible.</p>

<p>We&#39;ll build our web crawler piece-by-piece, but if you want a full preview of the source, check out it <a href="https://github.com/rossta/loves-enumerable/blob/master/examples/spider/spider.rb" target="_blank" rel="noopener noreferrer">on GitHub</a>.</p>

<p>Our <code>Spider</code> will maintain a set of urls to visit, data is collects, and a set of url &quot;handlers&quot; that will describe how each page should be processed. We&#39;ll take advantage of one external dependency, <code>mechanize</code>, to handle interaction with the pages we visit - to extract data, resolve urls, follow redirects, etc. Below is the <code>#enqueue</code> method to add urls and their handlers to a running list in our spider.</p>

<pre><code class="ruby">require &quot;mechanize&quot; # as of this writing, the latest release is 2.7.4

class Spider
  def enqueue(url, method)
    url = agent.resolve(url).to_s
    return if @handlers[url]
    @urls &lt;&lt; url
    @handlers[url] ||= { method: method, data: {} }
  end

  private

  def agent
    @agent ||= Mechanize.new
  end
end
</code></pre>

<p>As we process each page we&#39;ll need a way to record the structured data we extract from various pages. We&#39;ll expose a <code>#record</code> method append a hash of data to the <code>@results</code> array.</p>

<pre><code class="ruby">class Spider
  def record(data = {})
    @results &lt;&lt; data
  end
end
</code></pre>

<p>Since our <code>Spider</code> will only know how to enumerate urls and record data, we&#39;ll introduce a collaborator object to contain the implementation for consuming data for a specific site. For now, we&#39;ll call this object a &quot;processor&quot;. The processor will respond to the messages <code>#root</code> and <code>#handler</code> - the first url and handler method to enqueue for the spider, respectively. We&#39;ll also provide options for enforcing limits on the number of pages to crawl and the delay between each request.</p>

<pre><code class="ruby">class Spider
  REQUEST_INTERVAL = 5
  MAX_URLS = 1000

  def initialize(processor, attrs = {})
    @processor = processor

    @urls     = []
    @results  = []
    @handlers = {}

    @interval = attrs.fetch(:interval, REQUEST_INTERVAL)
    @max_urls = attrs.fetch(:max_urls, MAX_URLS)

    enqueue(processor.root, processor.handler)
  end
end
</code></pre>

      <h3 id="enumerator-two-ways" class="title title-h3">
        <a name="enumerator-two-ways" class="anchor" href="#enumerator-two-ways">       <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16">
       <path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path>
       </svg>
</a>
        Enumerator Two Ways
      </h3>
    
<p>Now for the real meat of our young <code>Spider</code>. The <code>#results</code> method is the key public interface: it enumerates the enqueued urls and yields members of the <code>@results</code> collection.</p>

<pre><code class="ruby">class Spider
  def results
    return enum_for(:results) unless block_given?

    index = @results.length
    enqueued_urls.each do |url, handler|

      # process url
      @processor.send(handler[:method], agent.get(url), handler[:data])

      if block_given? &amp;&amp; @results.length &gt; index
        yield @results.last
        index += 1
      end

      # crawl delay
      sleep @interval if @interval &gt; 0
    end
  end

  private

  def enqueued_urls
    Enumerator.new do |y|
      index = 0
      while index &lt; @urls.count &amp;&amp; index &lt;= @max_urls
        url = @urls[index]
        index += 1
        next unless url
        y.yield url, @handlers[url]
      end
    end
  end
end
</code></pre>

<p>An interesting thing to note is that the size of our url queue and the collected results may be growing as we crawl more pages. For the <code>#enqueued_urls</code> private method, we&#39;re using an <code>Enumerator</code> to wrap the logic for iterating over the list of <code>@urls</code> and maintaining state, like the <code>index</code>. The <code>Enumerator</code> class is well-suited to represent a lazily generated collection.</p>

<pre><code class="ruby">def enqueued_urls
  Enumerator.new do |y|
    # ...
  end
end
</code></pre>

<p>I find it to be a more expressive way to indicate we&#39;re enumerating values &quot;on demand&quot; as opposed to &quot;eagerly&quot;, like a typical collection.</p>

<p>Notice we&#39;re also returning an enumerator from <code>#results</code>:</p>

<pre><code class="ruby">def results
  return enum_for(:results) unless block_given?
  # ...
end
</code></pre>

<p>This technique provides the method caller to more flexibility when determining
how to handler the results. While you could pass a block to consume the
results, e.g., <code>spider.results { |r| puts r.inspect }</code>, this is an eager
operation. We&#39;d have to wait for all the pages to be processed before continuing
with the block. Returning an enumerator offers the potential to stream results
to something like a data store.</p>

<p>Why not include <code>Enumerable</code> in our <code>Spider</code> and implement <code>#each</code> instead? As pointed out in <a href="http://blog.arkency.com/2014/01/ruby-to-enum-for-enumerator/" target="_blank" rel="noopener noreferrer">Arkency&#39;s Stop including Enumerable, return Enumerator
instead</a>, our
<code>Spider</code> class doesn&#39;t itself represent a collection, so exposing the <code>#results</code>
method as an enumerator is more appropriate.</p>

      <h3 id="from-soup-to-net-results" class="title title-h3">
        <a name="from-soup-to-net-results" class="anchor" href="#from-soup-to-net-results">       <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16">
       <path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path>
       </svg>
</a>
        From Soup to Net Results
      </h3>
    
<p>Our <code>Spider</code> is now functional so we can move onto the details of extracting data from an actual website.</p>

<p>Our processor, <code>ProgrammableWeb</code> will be responsible for wrappin a <code>Spider</code> instance and extracting data from
the pages it visits. As mentioned previously, our processor will need to
define a root url and initial handler method, for which defaults are provided, and delegate the <code>#results</code> method to a <code>Spider</code> instance:</p>

<pre><code class="ruby">class ProgrammableWeb
  attr_reader :root, :handler

  def initialize(root: &quot;https://www.programmableweb.com/apis/directory&quot;, handler: :process_index, **options)
    @root = root
    @handler = handler
    @options = options
  end

  def results(&amp;block)
    spider.results(&amp;block)
  end

  private

  def spider
    @spider ||= Spider.new(self, @options)
  end
end
</code></pre>

<p><code>ProgrammableWeb</code> will define handler methods that deserialize a web page into additional urls and data to add to our collection of results.
Our spider will invoke the handlers (as seen above with <code>@processor.send(method, agent.get(url), data)</code>). Each handler method will have the following signature</p>

<pre><code class="ruby">def handler_method(page, data = {})
  # enqueue urls and/or record data
end
</code></pre>

<p>... where <code>page</code> is an instance of <code>Mechanize::Page</code> (<a href="http://docs.seattlerb.org/mechanize/Mechanize/Page.html" target="_blank" rel="noopener noreferrer">docs</a>) providing a number of methods for interacting with html content:</p>

<p>The root handler method, <code>ProgrammableWeb#process_index</code>, will extract api names in the
index list, enqueue api detail pages and additional, paginated indexes. As data
is collected, it may be passed on to handlers further down the tree via
<code>Spider#enqueue</code>.</p>

<pre><code class="ruby">def process_index(page, data = {})
  page.links_with(href: %r{\?page=\d+}).each do |link|
    spider.enqueue(link.href, :process_index)
  end

  page.links_with(href: %r{/api/\w+$}).each do |link|
    spider.enqueue(link.href, :process_api, name: link.text)
  end
end
</code></pre>

<p>To process api detail pages, we&#39;ll define a separate handler. Since these pages
will represent &quot;leaves&quot; in this exercise, we&#39;ll merge the data passed in with
that extracted from the page and pass it along to <code>Spider#record</code>.</p>

<pre><code class="ruby">def process_api(page, data = {})
  fields = page.search(&quot;#tabs-content .field&quot;).each_with_object({}) do |tag, o|
    key = tag.search(&quot;label&quot;).text.strip.downcase.gsub(%r{[^\w]+}, &#39; &#39;).gsub(%r{\s+}, &quot;_&quot;).to_sym
    val = tag.search(&quot;span&quot;).text
    o[key] = val
  end

  categories = page.search(&quot;article.node-api .tags&quot;).first.text.strip.split(/\s+/)

  spider.record data.merge(fields).merge(categories: categories)
end
</code></pre>

<p>As we saw earlier, recorded data is emitted in the <code>Spider#results</code> method.</p>

<p>Now we can make use of our <code>ProgrammableWeb</code> crawler as intended with simple
instantiation and the ability to enumerate results as a stream of data:</p>

<pre><code class="ruby">spider = ProgrammableWeb.new

spider.results.lazy.take(5).each_with_index do |result, i|
  puts &quot;%-3s: %s&quot; % [i, result.inspect]
end

# 0 : {:name=&gt;&quot;Facebook&quot;, :api_provider=&gt;&quot;http://facebook.com&quot;, :api_endpoint=&gt;&quot;http://api.facebook.com/restserver.php&quot;, :api_homepage=&gt;&quot;https://developers.facebook.com/&quot;, :primary_category=&gt;&quot;Social&quot;, :secondary_categories=&gt;&quot;Webhooks&quot;, :protocol_formats=&gt;&quot;JSON, REST&quot;, :ssl_support=&gt;&quot;Yes&quot;, :api_kits=&gt;&quot;http://developers.facebook.com/documentation.php?doc=clients&quot;, :api_forum=&gt;&quot;http://forum.developers.facebook.com/&quot;, :twitter_url=&gt;&quot;http://twitter.com/fbplatform&quot;, :developer_support=&gt;&quot;http://developers.facebook.com/group.php?gid=2205007948&quot;, :console_url=&gt;&quot;http://developers.facebook.com/tools/explorer&quot;, :authentication_mode=&gt;&quot;API Key, OAuth 2, Username/password&quot;, :categories=&gt;[&quot;Social&quot;, &quot;Webhooks&quot;]}
# 1 : {:name=&gt;&quot;LinkedIn&quot;, :api_provider=&gt;&quot;http://www.linkedin.com/&quot;, :api_endpoint=&gt;&quot;http://api.linkedin.com/v1/&quot;, :api_homepage=&gt;&quot;https://developer.linkedin.com/docs&quot;, :primary_category=&gt;&quot;Social&quot;, :secondary_categories=&gt;&quot;Enterprise&quot;, :protocol_formats=&gt;&quot;JSON, JSONP, REST, XML&quot;, :other_options=&gt;&quot;JavaScript&quot;, :ssl_support=&gt;&quot;Yes&quot;, :api_forum=&gt;&quot;https://developer.linkedin.com/forum&quot;, :twitter_url=&gt;&quot;https://twitter.com/linkedindev&quot;, :console_url=&gt;&quot;http://developer.linkedinlabs.com/jsapi-console/#examples/login/simple.html&amp;{&amp;quot;framework&amp;quot;:&amp;quot;platform.linkedin.com/in.js&amp;quot;,&amp;quot;frameworkurl&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;apikey&amp;quot;:&amp;quo&quot;, :authentication_mode=&gt;&quot;OAuth 2&quot;, :categories=&gt;[&quot;Social&quot;, &quot;Enterprise&quot;]}
# 2 : {:name=&gt;&quot;Skype&quot;, :api_provider=&gt;&quot;http://skype.com&quot;, :api_endpoint=&gt;&quot;http://skype.com&quot;, :api_homepage=&gt;&quot;http://www.skype.com/en/developer/&quot;, :primary_category=&gt;&quot;Telephony&quot;, :secondary_categories=&gt;&quot;Chat, Messaging, Video, Voice&quot;, :protocol_formats=&gt;&quot;Unspecified&quot;, :other_options=&gt;&quot;Skype proprietary&quot;, :ssl_support=&gt;&quot;Yes&quot;, :api_kits=&gt;&quot;https://developer.skype.com/Docs/Web https://developer.skype.com/wiki/Java_API&quot;, :api_forum=&gt;&quot;http://forum.skype.com/index.php?showforum=16&quot;, :developer_support=&gt;&quot;http://forum.skype.com/index.php?showforum=16&quot;, :authentication_mode=&gt;&quot;Unspecified&quot;, :categories=&gt;[&quot;Telephony&quot;, &quot;Chat,&quot;, &quot;Messaging,&quot;, &quot;Video,&quot;, &quot;Voice&quot;]}
# 3 : {:name=&gt;&quot;Twitter&quot;, :api_provider=&gt;&quot;http://twitter.com&quot;, :api_endpoint=&gt;&quot;http://twitter.com/statuses/&quot;, :api_homepage=&gt;&quot;https://dev.twitter.com/rest/public&quot;, :primary_category=&gt;&quot;Social&quot;, :secondary_categories=&gt;&quot;Blogging&quot;, :protocol_formats=&gt;&quot;Atom, JSON, REST, RSS, XML&quot;, :ssl_support=&gt;&quot;No&quot;, :api_kits=&gt;&quot;ActionScript&quot;, :api_forum=&gt;&quot;http://groups.google.com/group/twitter-development-talk&quot;, :twitter_url=&gt;&quot;http://twitter.com/twitterapi&quot;, :contact_email=&gt;&quot;api@twitter.com&quot;, :console_url=&gt;&quot;https://dev.twitter.com/console&quot;, :authentication_mode=&gt;&quot;OAuth 2, HTTP Basic Auth, OAuth&quot;, :categories=&gt;[&quot;Social&quot;, &quot;Blogging&quot;]}
# 4 : {:name=&gt;&quot;YouTube&quot;, :api_provider=&gt;&quot;http://www.google.com&quot;, :api_endpoint=&gt;&quot;http://gdata.youtube.com/feeds/&quot;, :api_homepage=&gt;&quot;https://developers.google.com/youtube/&quot;, :primary_category=&gt;&quot;Video&quot;, :secondary_categories=&gt;&quot;Media&quot;, :protocol_formats=&gt;&quot;Atom, RSS, JSON, XML, GData&quot;, :other_options=&gt;&quot;Atom Publishing Protocol (Atom/RSS)&quot;, :ssl_support=&gt;&quot;No&quot;, :api_kits=&gt;&quot;Java, PHP Python, Ruby, ActionScript&quot;, :api_forum=&gt;&quot;http://groups.google.com/group/youtube-api/&quot;, :twitter_url=&gt;&quot;https://twitter.com/YouTubeDev/&quot;, :developer_support=&gt;&quot;http://code.google.com/support/bin/topic.py?topic=12357&quot;, :console_url=&gt;&quot;http://code.google.com/apis/ajax/playground/?exp=youtube#simple_embed&quot;, :authentication_mode=&gt;&quot;OAuth2&quot;, :categories=&gt;[&quot;Video&quot;, &quot;Media&quot;]}
</code></pre>

      <h3 id="wrapping-up" class="title title-h3">
        <a name="wrapping-up" class="anchor" href="#wrapping-up">       <svg aria-hidden="true" class="octicon octicon-link" height="16" version="1.1" viewBox="0 0 16 16" width="16">
       <path d="M4 9h1v1h-1c-1.5 0-3-1.69-3-3.5s1.55-3.5 3-3.5h4c1.45 0 3 1.69 3 3.5 0 1.41-0.91 2.72-2 3.25v-1.16c0.58-0.45 1-1.27 1-2.09 0-1.28-1.02-2.5-2-2.5H4c-0.98 0-2 1.22-2 2.5s1 2.5 2 2.5z m9-3h-1v1h1c1 0 2 1.22 2 2.5s-1.02 2.5-2 2.5H9c-0.98 0-2-1.22-2-2.5 0-0.83 0.42-1.64 1-2.09v-1.16c-1.09 0.53-2 1.84-2 3.25 0 1.81 1.55 3.5 3 3.5h4c1.45 0 3-1.69 3-3.5s-1.5-3.5-3-3.5z"></path>
       </svg>
</a>
        Wrapping up
      </h3>
    
<p>I admit, it&#39;s arguable that this implementation is &quot;simple&quot;. Skorks provided a straightforward, recursive solution to consume unstructured content. Our approach is iterative and requires some work up front to define which links to consume and how to process them with &quot;handlers&quot;. However, we were able to achieve an extensible, flexible tool with a nice separation of concerns and a familiar, enumerable interface.</p>

<p>Modeling results from a multi-level page crawl as a collection may not work for every use case, but, for this exercise, it serves as a nice abstraction. It would now be trivial to take our <code>Spider</code> class and implement a new processor for a site like <a href="https://rubygems.org" target="_blank" rel="noopener noreferrer">rubygems.org</a> or <a href="https://craigslist.org" target="_blank" rel="noopener noreferrer">craigslist</a> and stream the results to a database like <a href="http://redis.io" target="_blank" rel="noopener noreferrer">Redis</a> or <a href="http://ruby-doc.org/stdlib-2.3.0/libdoc/yaml/rdoc/YAML/Store.html" target="_blank" rel="noopener noreferrer"><code>YAML::Store</code></a>.</p>

<p>Try it yourself and let me know what you think of this approach (<a href="https://github.com/rossta/loves-enumerable/blob/master/examples/spider/spider.rb" target="_blank" rel="noopener noreferrer">full source</a>).</p>

  </article>
  <section class="mb-12">
    <p class="text-right">
      <a href="https://twitter.com/intent/tweet?text=How%20to%20write%20a%20simple%20web%20crawler%20in%20Ruby%20-%20revisited%20-%20rossta.net&amp;url=https%3A%2F%2Frossta.net%2Fblog%2Fhow-to-write-a-simple-web-crawler-in-ruby-revisited.html" class="font-bold" target="_blank" rel="noopener noreferrer">Discuss it on Twitter</a>
      &middot;
      <span class="italic font-light">
          Part of the <a href="/blog/series/enumerable.html">Enumerable</a> series.
        Published on Jan 27, 2016
      </span>
    </p>
  </section>
  <section class="signup-form-standalone hero">
    <script src="https://f.convertkit.com/ckjs/ck.5.js" async></script>
<form
  action="https://app.convertkit.com/forms/818387/subscriptions?ref=Ruby"
  class="seva-form formkit-form"
  method="post"
  data-sv-form="818387"
  data-uid="cda82aafbf"
  data-format="inline"
  data-version="5"
  data-options="{&quot;settings&quot;:{&quot;after_subscribe&quot;:{&quot;action&quot;:&quot;message&quot;,&quot;success_message&quot;:&quot;Success! Now check your email to confirm your subscription.&quot;,&quot;redirect_url&quot;:&quot;&quot;},&quot;modal&quot;:{&quot;trigger&quot;:&quot;timer&quot;,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:&quot;300&quot;,&quot;devices&quot;:null,&quot;show_once_every&quot;:&quot;7&quot;},&quot;recaptcha&quot;:{&quot;enabled&quot;:false},&quot;return_visitor&quot;:{&quot;action&quot;:&quot;show&quot;,&quot;custom_content&quot;:&quot;&quot;},&quot;slide_in&quot;:{&quot;display_in&quot;:null,&quot;trigger&quot;:null,&quot;scroll_percentage&quot;:null,&quot;timer&quot;:null,&quot;devices&quot;:null,&quot;show_once_every&quot;:null}}}"
>
  <div>
    <div class="mb-4">
        <h2 class="mb-8">
  Need help with JavaScript on Rails?
</h2>
<p class="mb-4">My name is <strong>Ross Kaffenberger</strong>.</p>

<p class="mb-4">
  I teach full stack web developers about frontend tools and performance,
  especially at the intersection of <strong>JavaScript</strong> and <strong>Ruby on Rails</strong>.
</p>

<p>
  Subscribe to stay in the loop.
</p>

    </div>
    <ul class="formkit-alert formkit-alert-error" data-element="errors" data-group="alert"></ul>
    <div data-element="fields" data-stacked="false" class="seva-fields formkit-fields">
      <div class="formkit-field">
        <label for="email_address" class="sr-only">Email address</label>
        <input
          class="formkit-input"
          id="email_address"
          name="email_address"
          placeholder="Your email address"
          required=""
          type="email"
          style="border-color: rgb(227, 227, 227); border-radius: 4px; color: rgb(0, 0, 0); font-weight: 400;"
        />
      </div>
      <button
        data-element="submit"
        class="formkit-submit button button-green"
      >
        <div class="formkit-spinner">
          <div></div>
          <div></div>
          <div></div>
        </div>
        <span>Subscribe</span>
      </button>
    </div>
  </div>
  <style>
  </style>
    <input type="hidden" name="tags[]" value="733960" />
  <input type="hidden" aria-label="URL" name="fields[url]" placeholder="URL" value="https://rossta.net/blog/how-to-write-a-simple-web-crawler-in-ruby-revisited.html" />
</form>


  </section>
  <section class="index-posts mb-24">
    <h2 class="mb-8">More posts</h2>
      <article class="index-post">
    <header class="index-title">
      <a href="/blog/clojure-iterate-in-ruby.html">Clojure's iterate in Ruby</a>
    </header>
      <p>Implementing the Clojure sequence functions, iterate, with Ruby's Enumerator to emulate sequences</p>
  </article>
  <article class="index-post">
    <header class="index-title">
      <a href="/blog/recurring-events-in-ruby.html">Recurring events in Ruby</a>
    </header>
      <p>Montrose is an easy-to-use library for defining recurring events in Ruby. It uses a simple chaining system for building recurrences, inspired heavily by the design principles of HTTP.rb and rule definitions available in the Recurrence gem.</p>
  </article>
  <article class="index-post">
    <header class="index-title">
      <a href="/blog/whats-new-in-ruby-2-3-enumerable.html">What's new in Ruby 2.3 Enumerable</a>
    </header>
      <p>Ruby 2.3 introduced a couple new additions to the Enumerable API that provide some nice variations on existing methods</p>
  </article>

  </section>
  <article class="mb-24">
      <figure>
        <img src="/assets/images/blog/stock/spider-web-pexels-photo.jpg" loading="lazy" alt="" />
      </figure>
  </article>

    </main>
    <footer class="bg-silver text-xs">
  <div class="layout container p-6">
    <img src="/assets/images/turtle-logo.svg" loading="lazy" class="turtle w-8 mb-6" alt="" />
    <section class="lg:flex lg:justify-between">
      <section class="mb-8">
        <h5 class="font-bold mb-4">Most Popular</h5>
        <ul>
            <li class="mb-1"><a href="/blog/why-does-rails-install-both-webpacker-and-sprockets.html">Why does Rails 6 include both Webpacker and Sprockets?</a></li>
            <li class="mb-1"><a href="/blog/reasons-to-switch-to-webpacker.html">25 reasons to switch to Webpack(er)</a></li>
            <li class="mb-1"><a href="/blog/webpacker-with-bootstrap.html">Using Bootstrap with Rails Webpacker</a></li>
            <li class="mb-1"><a href="/blog/importing-images-with-webpacker.html">Importing images with Webpacker</a></li>
            <li class="mb-1"><a href="/blog/from-sprockets-to-webpack.html">How we switched from Sprockets to Webpacker</a></li>
        </ul>
      </section>
      <section class="mb-8">
        <h5 class="font-bold mb-4">
          <a class="text-gray-900 hover:text-gray-700" href="blog/tags.html">
            Categories
          </a>
        </h5>
        <ul>
            <li class="mb-1"><a href="/blog/tags/rails.html">Rails</a></li>
            <li class="mb-1"><a href="/blog/tags/ruby.html">Ruby</a></li>
            <li class="mb-1"><a href="/blog/tags/webpack.html">Webpack</a></li>
            <li class="mb-1"><a href="/blog/tags/javascript.html">JavaScript</a></li>
            <li class="mb-1"><a href="/blog/tags/vue.html">Vue</a></li>
        </ul>
      </section>
      <section class="mb-8">
        <h5 class="font-bold mb-4">Contact</h5>
        <ul>
          <li class="mb-1"><a target="_blank" href="mailto:ross@rossta.net" rel="me noopener nofollow">email</a></li>
          <li class="mb-1"><a target="_blank" href="https://twitter.com/rossta" rel="me noopener nofollow">twitter</a></li>
          <li class="mb-1"><a target="_blank" href="https://github.com/rossta" rel="me noopener nofollow">github</a></li>
          <li class="mb-1"><a target="_blank" href="https://www.linkedin.com/in/rosskaffenberger" rel="me noopener nofollow">linkedin</a></li>
          <li class="mb-1"><a target="_blank" href="https://stackoverflow.com/users/771838/rossta?tab=profile" rel="me noopener nofollow">stackoverflow</a></li>
        </ul>
      </section>
    </section>
    <p class="copyright text-center text-xs font-light">
      © 2023 Ross Kaffenberger. All rights reserved.
    </p>
  </div>
</footer>

    <script src="/js/runtime.5be4ddc4f7ddf44ecbe4.js"></script>"<script src="/js/app.d1ef27c9a26cf7bc4240.js"></script>"
    
  </body>
</html>
